{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "def build_generator():\n",
        "    input_shape = (256, 256, 3)  # Input image shape\n",
        "    num_filters = 64  # Number of filters in the first layer\n",
        "    num_downsampling = 2  # Number of downsampling layers\n",
        "    num_residual_blocks = 9  # Number of residual blocks\n",
        "    num_upsampling = 2  # Number of upsampling layers\n",
        "    output_channels = 3  # Number of output channels (RGB)\n",
        "\n",
        "    # Input layer\n",
        "    inputs = keras.Input(shape=input_shape)\n",
        "\n",
        "    # Downsampling\n",
        "    x = layers.Conv2D(num_filters, 7, padding=\"same\")(inputs)\n",
        "    x = layers.Activation(\"relu\")(x)\n",
        "\n",
        "    for _ in range(num_downsampling):\n",
        "        # Convolutional layers with downsampling\n",
        "        num_filters *= 2\n",
        "        x = layers.Conv2D(num_filters, 3, strides=2, padding=\"same\")(x)\n",
        "        x = layers.BatchNormalization()(x)\n",
        "        x = layers.Activation(\"relu\")(x)\n",
        "\n",
        "    # Residual blocks\n",
        "    for _ in range(num_residual_blocks):\n",
        "        x = residual_block(x, num_filters)\n",
        "\n",
        "    # Upsampling\n",
        "    for _ in range(num_upsampling):\n",
        "        # Convolutional layers with upsampling\n",
        "        num_filters //= 2\n",
        "        x = layers.Conv2DTranspose(num_filters, 3, strides=2, padding=\"same\")(x)\n",
        "        x = layers.BatchNormalization()(x)\n",
        "        x = layers.Activation(\"relu\")(x)\n",
        "\n",
        "    # Output layer\n",
        "    x = layers.Conv2D(output_channels, 7, padding=\"same\")(x)\n",
        "    outputs = layers.Activation(\"tanh\")(x)\n",
        "\n",
        "    # Build the generator model\n",
        "    generator = keras.Model(inputs, outputs, name=\"generator\")\n",
        "    return generator\n",
        "\n",
        "def residual_block(x, num_filters):\n",
        "    # Residual block with skip connections\n",
        "    y = x\n",
        "\n",
        "    # First convolutional layer\n",
        "    x = layers.Conv2D(num_filters, 3, padding=\"same\")(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.Activation(\"relu\")(x)\n",
        "\n",
        "    # Second convolutional layer\n",
        "    x = layers.Conv2D(num_filters, 3, padding=\"same\")(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "\n",
        "    # Skip connection\n",
        "    x = layers.Add()([x, y])\n",
        "    x = layers.Activation(\"relu\")(x)\n",
        "    return x"
      ],
      "metadata": {
        "id": "G08rEBVMBsxO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def build_discriminator():\n",
        "    input_shape = (256, 256, 3)  # Input image shape\n",
        "    num_filters = 64  # Number of filters in the first layer\n",
        "    num_downsampling = 3  # Number of downsampling layers\n",
        "    output_channels = 1  # Number of output channels (binary classification)\n",
        "\n",
        "    # Input layer\n",
        "    inputs = keras.Input(shape=input_shape)\n",
        "\n",
        "    # Convolutional layers\n",
        "    x = layers.Conv2D(num_filters, 4, strides=2, padding=\"same\")(inputs)\n",
        "    x = layers.LeakyReLU(alpha=0.2)(x)\n",
        "\n",
        "    for i in range(1, num_downsampling):\n",
        "        # Convolutional layers with downsampling\n",
        "        num_filters *= 2\n",
        "        x = layers.Conv2D(num_filters, 4, strides=2, padding=\"same\")(x)\n",
        "        x = layers.BatchNormalization()(x)\n",
        "        x = layers.LeakyReLU(alpha=0.2)(x)\n",
        "\n",
        "    # Output layer\n",
        "    x = layers.Conv2D(output_channels, 4, strides=1, padding=\"same\")(x)\n",
        "    outputs = layers.Activation(\"sigmoid\")(x)\n",
        "\n",
        "    # Build the discriminator model\n",
        "    discriminator = keras.Model(inputs, outputs, name=\"discriminator\")\n",
        "    return discriminator\n",
        "\n",
        "def discriminator_loss(real_output, fake_output):\n",
        "    real_loss = cross_entropy(tf.ones_like(real_output), real_output)\n",
        "    fake_loss = cross_entropy(tf.zeros_like(fake_output), fake_output)\n",
        "    total_loss = real_loss + fake_loss\n",
        "    return total_loss\n",
        "    \n",
        "def generator_loss(fake_output):\n",
        "    gen_loss = cross_entropy(tf.ones_like(fake_output), fake_output)\n",
        "    return gen_loss"
      ],
      "metadata": {
        "id": "DhtqXp52CFzn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Build the generators\n",
        "generator_AB = build_generator()  # Real to cartoon\n",
        "generator_BA = build_generator()  # Cartoon to real\n",
        "\n",
        "# Build the discriminators\n",
        "discriminator_A = build_discriminator()  # Real discriminator\n",
        "discriminator_B = build_discriminator()  # Cartoon discriminator\n",
        "\n",
        "# Define the loss functions (binary cross-entropy)\n",
        "cross_entropy = keras.losses.BinaryCrossentropy(from_logits=True)"
      ],
      "metadata": {
        "id": "A9UK2xmfCQgd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Optimizers for generators and discriminators\n",
        "generator_optimizer = keras.optimizers.Adam(learning_rate=2e-4, beta_1=0.5)\n",
        "discriminator_optimizer = keras.optimizers.Adam(learning_rate=2e-4, beta_1=0.5)"
      ],
      "metadata": {
        "id": "3o5OcyrCC0CR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_step(real_images, cartoon_images):\n",
        "    with tf.GradientTape(persistent=True) as tape:\n",
        "        # Generate fake images\n",
        "        fake_cartoons = generator_AB(real_images)\n",
        "        fake_real = generator_BA(cartoon_images)\n",
        "\n",
        "        # Calculate cycle consistency loss\n",
        "        cycle_real_images = generator_BA(fake_cartoons)\n",
        "        cycle_cartoon_images = generator_AB(fake_real)\n",
        "        cycle_loss = tf.reduce_mean(tf.abs(real_images - cycle_real_images)) + tf.reduce_mean(tf.abs(cartoon_images - cycle_cartoon_images))\n",
        "\n",
        "        # Calculate total generator loss\n",
        "        gen_loss = generator_loss(fake_output)\n",
        "\n",
        "        # Calculate discriminator losses\n",
        "        disc_loss_A = discriminator_loss(real_output, fake_output)\n",
        "        disc_loss_B = discriminator_loss(real_output, fake_output)\n",
        "\n",
        "    # Calculate the gradients for generators and discriminators\n",
        "    generator_gradients = tape.gradient(gen_loss, generator_AB.trainable_variables)\n",
        "    discriminator_gradients_A = tape.gradient(disc_loss_A, discriminator_A.trainable_variables)\n",
        "    discriminator_gradients_B = tape.gradient(disc_loss_B, discriminator_B.trainable_variables)\n",
        "\n",
        "    # Update the weights of the generators and discriminators\n",
        "    generator_optimizer.apply_gradients(zip(generator_gradients, generator_AB.trainable_variables))\n",
        "    discriminator_optimizer.apply_gradients(zip(discriminator_gradients_A, discriminator_A.trainable_variables))\n",
        "    discriminator_optimizer.apply_gradients(zip(discriminator_gradients_B, discriminator_B.trainable_variables))\n",
        "\n",
        "# Build the generators\n",
        "generator_AB = build_generator()  # Real to cartoon\n",
        "generator_BA = build_generator()  # Cartoon to real\n",
        "\n",
        "# Build the discriminators\n",
        "discriminator_A = build_discriminator()  # Real discriminator\n",
        "discriminator_B = build_discriminator()  # Cartoon discriminator\n",
        "\n",
        "# Define the loss functions (binary cross-entropy)\n",
        "cross_entropy = keras.losses.BinaryCrossentropy(from_logits=True)\n",
        "\n",
        "# Training loop\n",
        "def train(dataset, epochs):\n",
        "    for epoch in range(epochs):\n",
        "        for real_images, cartoon_images in dataset:\n",
        "            train_step(real_images, cartoon_images)\n",
        "\n"
      ],
      "metadata": {
        "id": "3gR5K7gTDAeu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# first methode"
      ],
      "metadata": {
        "id": "KVdfCh4wENvl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
        "from tensorflow.keras.preprocessing.image import random_rotation, random_zoom\n",
        "\n",
        "def preprocess_image(image_path, target_size):\n",
        "    # Load the image and resize\n",
        "    img = load_img(image_path, target_size=target_size)\n",
        "    # Convert the image to array\n",
        "    img = img_to_array(img)\n",
        "    # Normalize the pixel values to the range of [-1, 1]\n",
        "    img = (img - 127.5) / 127.5\n",
        "    return img\n",
        "\n",
        "def preprocess_dataset(image_paths, target_size):\n",
        "    images = []\n",
        "    for image_path in image_paths:\n",
        "        # Preprocess each image\n",
        "        img = preprocess_image(image_path, target_size)\n",
        "        images.append(img)\n",
        "    return np.array(images)\n",
        "\n",
        "def augment_dataset(images, batch_size):\n",
        "    augmented_images = []\n",
        "    for image in images:\n",
        "        # Random rotation\n",
        "        image = random_rotation(image, 30, row_axis=0, col_axis=1, channel_axis=2)\n",
        "        # Random zoom\n",
        "        image = random_zoom(image, (0.8, 1.2), row_axis=0, col_axis=1, channel_axis=2)\n",
        "        augmented_images.append(image)\n",
        "    return np.array(augmented_images)\n",
        "\n",
        "# Example usage\n",
        "real_image_paths = ['path/to/real_image1.jpg', 'path/to/real_image2.jpg', ...]\n",
        "cartoon_image_paths = ['path/to/cartoon_image1.jpg', 'path/to/cartoon_image2.jpg', ...]\n",
        "\n",
        "target_size = (256, 256)  # Desired image size\n",
        "\n",
        "# Preprocess the real images\n",
        "real_images = preprocess_dataset(real_image_paths, target_size)\n",
        "\n",
        "# Preprocess the cartoon images\n",
        "cartoon_images = preprocess_dataset(cartoon_image_paths, target_size)\n",
        "\n",
        "# Augment the datasets\n",
        "real_images_augmented = augment_dataset(real_images, batch_size)\n",
        "cartoon_images_augmented = augment_dataset(cartoon_images, batch_size)\n",
        "\n"
      ],
      "metadata": {
        "id": "IBlSfbQmDg3J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "epochs = 100\n",
        "batch_size = 16\n",
        "\n",
        "# Create your dataset using augmented real and cartoon images\n",
        "dataset = tf.data.Dataset.from_tensor_slices((real_images_augmented, cartoon_images_augmented))\n",
        "dataset = dataset.shuffle(buffer_size=num_samples * 2).batch(batch_size)\n",
        "\n",
        "# Training loop\n",
        "for epoch in range(epochs):\n",
        "    for real_images, cartoon_images in dataset:\n",
        "        # Perform training step\n",
        "        train_step(real_images, cartoon_images)"
      ],
      "metadata": {
        "id": "4c2bypEaFmbk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# deusieme methode"
      ],
      "metadata": {
        "id": "i2oBfQkXESWB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "# Set the paths to your real and cartoon image directories\n",
        "real_image_dir = 'path/to/real_images'\n",
        "cartoon_image_dir = 'path/to/cartoon_images'\n",
        "\n",
        "# Set the target size for resizing the images\n",
        "target_size = (256, 256)\n",
        "\n",
        "# Set the batch size for training\n",
        "batch_size = 16\n",
        "\n",
        "# Create data generators for real and cartoon images\n",
        "data_generator = ImageDataGenerator(preprocessing_function=lambda x: (x - 127.5) / 127.5)\n",
        "\n",
        "real_data_generator = data_generator.flow_from_directory(\n",
        "    real_image_dir,\n",
        "    target_size=target_size,\n",
        "    batch_size=batch_size,\n",
        "    class_mode=None,\n",
        "    shuffle=True\n",
        ")\n",
        "\n",
        "cartoon_data_generator = data_generator.flow_from_directory(\n",
        "    cartoon_image_dir,\n",
        "    target_size=target_size,\n",
        "    batch_size=batch_size,\n",
        "    class_mode=None,\n",
        "    shuffle=True\n",
        ")\n",
        "\n",
        "# Combine the real and cartoon data generators into a single dataset generator\n",
        "dataset_generator = zip(real_data_generator, cartoon_data_generator)"
      ],
      "metadata": {
        "id": "Ag1PESGhD7X0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "6FJ92wNkDiRI"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}